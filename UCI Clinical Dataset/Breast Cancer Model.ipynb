{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83d1fc20",
   "metadata": {},
   "source": [
    "# Breast Cancer Coimbra Dataset Analysis\n",
    "This notebook demonstrates the exploratory data analysis (EDA) and model building for breast cancer prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8211a6de",
   "metadata": {},
   "source": [
    "## Step 1: Load and Inspect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7eb8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "csv_file_path = '/mnt/data/breast_cancer_coimbra/dataR2.csv'\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Show the first few rows and basic information\n",
    "df.head(), df.info(), df.describe(), df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130d9271",
   "metadata": {},
   "source": [
    "## Step 2: Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0941b455",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Checking if there are any missing values and filling them (if necessary)\n",
    "missing_values = df.isnull().sum()\n",
    "missing_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9d3be8",
   "metadata": {},
   "source": [
    "## Step 3: Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea755607",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot histograms for numerical columns\n",
    "df.hist(bins=20, figsize=(10, 8))\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3f5716",
   "metadata": {},
   "source": [
    "## Step 4: Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b826c560",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate correlation matrix\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "# Display heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10950a1b",
   "metadata": {},
   "source": [
    "## Step 5: Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956260f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the features (X) and target (y)\n",
    "X = df.drop('Classification', axis=1)\n",
    "y = df['Classification']\n",
    "\n",
    "# Split the data into training, validation, and testing sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "(X_train.shape, X_val.shape, X_test.shape), (y_train.shape, y_val.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fd94c9",
   "metadata": {},
   "source": [
    "## Step 6: Train Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27be473b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Train the model\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "accuracy, report, conf_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c59444",
   "metadata": {},
   "source": [
    "## Step 7: Make Recommendations Based on Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12445f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to make recommendations based on prediction\n",
    "def make_recommendation(patient_data):\n",
    "    # Predict the cancer classification and probability\n",
    "    prediction = model.predict(patient_data)\n",
    "    probability = model.predict_proba(patient_data)\n",
    "\n",
    "    # Generate recommendation based on the prediction\n",
    "    if prediction == 1:\n",
    "        recommendation = \"Recommendation: The patient is at high risk for breast cancer. Further diagnostic tests are recommended.\"\n",
    "    else:\n",
    "        recommendation = \"Recommendation: The patient is at low risk. Continue regular health monitoring.\"\n",
    "    \n",
    "    return prediction, probability, recommendation\n",
    "\n",
    "# Example: New patient data for prediction (replace with actual feature values)\n",
    "new_patient = [[60, 24.5, 90, 15, 3.4, 12.5, 4.1, 8.3, 550]]  # Replace with real feature values\n",
    "prediction, probability, recommendation = make_recommendation(new_patient)\n",
    "\n",
    "prediction, probability, recommendation\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
